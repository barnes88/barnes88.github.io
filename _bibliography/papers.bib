---
---
@INPROCEEDINGS{HSU,
  author={Barnes, Aaron and Shen, Fangjia and Rogers, Timothy G.},
  booktitle={2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
  title={Extending GPU Ray-Tracing Units for Hierarchical Search Acceleration}, 
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Specialized ray-tracing acceleration units have become a common feature in GPU hardware, enabling real-time ray-tracing of complex scenes for the first time. The ray-tracing unit accelerates the traversal of a hierarchical tree data structure called a bounding volume hierarchy to determine whether rays have intersected triangle primitives. Hierarchical search algorithms are a fundamental software pattern common in many important domains, such as recommendation systems and point cloud registration, but are difficult for GPUs to accelerate because they are characterized by extensive branching and recursion. The ray-tracing unit overcomes these limitations with specialized hardware to traverse hierarchical data structures efficiently, but is mired by a highly specialized graphics API, which is not readily adaptable to general-purpose computation. We present the Hierarchical Search Unit (HSU), a flexible datapath to accelerate a more general class of hierarchical search algorithms, of which ray-tracing is one.  We synthesize a baseline ray-intersection datapath and maximize functional unit reuse while extending the ray-tracing unit to support additional computations and a more general set of instructions. We demonstrate that the unit can improve the performance of three hierarchical search data structures in approximate nearest neighbors search algorithms and a B-tree key-value store index. For a minimal extension to the existing unit, our HSU improves the state-of-the-art GPU approximate nearest neighbor implementation by an average of 24.8% using the GPU's general computing interface.},
  keywords={},
  doi={},
  ISSN={},
  link={https://ieeexplore.ieee.org/abstract/document/10764676},
  pdf={AaronBarnes_MICRO24.pdf},
  slides={AaronBarnes_MICRO24.pptx},
  month={Nov},}

@INPROCEEDINGS{10070957,
  author={Barnes, Aaron and Shen, Fangjia and Rogers, Timothy G.},
  booktitle={2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}, 
  title={Mitigating GPU Core Partitioning Performance Effects}, 
  year={2023},
  volume={},
  number={},
  pages={530-542},
  abstract={Modern GPU Streaming Multiprocessors (SMs) have several warp schedulers, execution units, and register file banks. To reduce area and energy-consumption, recent generations divide SMs into sub-cores. Each sub-core contains a distinct warp scheduler, register file, and execution units, sharing L1 memory and scratchpad resources with sub-cores in the same SM. Although partitioning the SM into sub-cores decreases the area and energy demands of larger SMs, it comes at a performance cost. Warps assigned to the SM have access to a fraction of the SM’s resources, resulting in contention and imbalance issues. In this paper, we examine the effect SM sub-division has on performance and propose novel mechanisms to mitigate the negative impacts. We identify four orthogonal effects caused by sub-dividing SMs and demonstrate that two of these effects have a significant impact on performance in practice. Based on these findings, we propose register-bank-aware warp scheduling to avoid bank conflicts that arise when instruction operands are placed in the limited number of register file banks available to each sub-core, and randomly hashed sub-core assignment to mitigate imbalance issues. Our intelligent scheduling mechanisms result in an average 11.2% speedup across a diverse set of applications capturing 81% of the performance lost to SM sub-division.},
  keywords={},
  doi={10.1109/HPCA56546.2023.10070957},
  ISSN={2378-203X},
  link={https://ieeexplore.ieee.org/document/10070957},
  pdf={AaronBarnes_HPCA23.pdf},
  slides={AaronBarnes_HPCA23.pptx},
  month={Feb},}


@INPROCEEDINGS{9923866,
  author={Khairy, Mahmoud and Alawneh, Ahmad and Barnes, Aaron and Rogers, Timothy G.},
  booktitle={2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO)}, 
  title={SIMR: Single Instruction Multiple Request Processing for Energy-Efficient Data Center Microservices}, 
  year={2022},
  volume={},
  number={},
  pages={441-463},
  abstract={Contemporary data center servers process thousands of similar, independent requests per minute. In the interest of programmer productivity and ease of scaling, workloads in data centers have shifted from single monolithic processes toward a micro and nanoservice software architecture. As a result, single servers are now packed with many threads executing the same, relatively small task on different data.State-of-the-art data centers run these microservices on multi-core CPUs. However, the flexibility offered by traditional CPUs comes at an energy-efficiency cost. The Multiple Instruction Multiple Data execution model misses opportunities to aggregate the similarity in contemporary microservices. We observe that the Single Instruction Multiple Thread execution model, employed by GPUs, provides better thread scaling and has the potential to reduce frontend and memory system energy consumption. However, contemporary GPUs are ill-suited for the latency-sensitive microservice space.To exploit the similarity in contemporary microservices, while maintaining acceptable latency, we propose the Request Processing Unit (RPU). The RPU combines elements of out-of-order CPUs with lockstep thread aggregation mechanisms found in GPUs to execute microservices in a Single Instruction Multiple Request (SIMR) fashion. To complement the RPU, we also propose a SIMR-aware software stack that uses novel mechanisms to batch requests based on their predicted control-flow, split batches based on predicted latency divergence and map per-request memory allocations to maximize coalescing opportunities. Our resulting RPU system processes 5. 7 × more requests/joule than multi-core CPUs, while increasing single thread latency by only 1. ×.},
  keywords={},
  doi={10.1109/MICRO56248.2022.00040},
  ISSN={},
  link={https://ieeexplore.ieee.org/document/9923866},
  pdf={https://mkhairy.github.io/Docs/SIMR.pdf},
  month={Oct},}